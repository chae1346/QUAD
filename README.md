export ROS_MASTER_URI=http://10.224.113.161:11311
export ROS_HOSTNAME=10.224.113.161
export ROS_IP=10.223.114.125 # KMU

vim ~/.bashrc

source ~/.bashrc

echo $ROS_MASTER_URI
echo $ROS_HOSTNAME
echo $ROS_IP


cd catkin_ws/QUAD/src/yolov5



알고리즘 개요
키보드 입력을 기반으로 동작 수행:

사용자가 키보드로 번호(1, 2, ...)를 입력하면 해당 번호에 대응하는 구역으로 드론이 이동.
q를 누르면 드론이 착륙하고 모든 동작이 종료.
구역 이동 및 동작:

드론은 SLAM을 통해 맵핑된 환경 정보를 이용하여 지정된 구역으로 오프보드 주행.
지정된 구역에 도착하면 호버링 유지.
이미지 수집 및 객체 탐지:

구역에 도착한 드론이 웹캠을 활성화하여 실시간 이미지를 퍼블리시.
detect.py가 해당 이미지를 받아서 YOLO 모델로 객체 탐지를 수행.
탐지된 결과는 사람이 확인하기 쉽게 표나 리스트 형태로 출력.
탐지 완료 후 종료:

객체 탐지가 끝나면 detect.py가 /detection_done 메시지를 발행.
webcam 노드가 이 메시지를 구독하여 웹캠을 종료.
반복:

사용자가 다음 구역 번호를 입력하면 해당 구역으로 이동.
이 과정을 반복.
작업 종료:

사용자가 q를 입력하면 드론이 착륙하며, **주행 코드와 detect.py**가 모두 종료.
단계별 설명
키보드 입력 감지:

Python에서 키보드 입력을 감지.
입력된 숫자에 따라 드론의 동작이 달라짐:
1, 2, ...: 구역 이동 명령.
q: 시스템 종료 명령.
드론의 이동 및 호버링:

SLAM을 통해 이미 맵핑된 환경 정보를 사용.
지정된 번호의 구역으로 드론이 오프보드 주행.
구역에 도착하면 호버링 상태로 대기.
웹캠 활성화:

드론이 구역에 도착하면 웹캠을 켜서 실시간 이미지를 퍼블리시.
이미지는 ROS의 /usb_cam/image_raw 토픽으로 전송.
탐지 작업 수행:

detect.py는 /usb_cam/image_raw를 구독.
YOLO 객체 탐지 모델을 통해 이미지를 분석하고, 탐지된 객체를 리스트 또는 표로 표시.
탐지 종료 신호:

탐지가 완료되면 detect.py가 /detection_done 메시지를 발행.
webcam 노드는 이를 구독하여 웹캠을 종료.
반복 및 종료:

사용자 입력에 따라 다음 구역으로 이동.
q를 입력하면 드론이 착륙하면서 모든 코드가 종료.
추가 사항
키보드 입력은 Python에서 keyboard 라이브러리나 input()을 사용하여 처리 가능.
탐지 결과를 사람이 쉽게 확인할 수 있도록 Tkinter 위젯이나 터미널에 출력.
ROS를 사용하여 노드 간 통신을 관리 (/detection_done, /usb_cam/image_raw 등).
모든 동작은 키보드 입력 → 이동 → 탐지 → 종료라는 순서를 따름.

